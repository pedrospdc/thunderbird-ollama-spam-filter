<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <style>
    body { padding: 16px; font-family: system-ui, sans-serif; max-width: 480px; font-size: 14px; }
    h2 { margin-top: 0; }
    label { display: block; margin-top: 14px; font-weight: 600; }
    input, select, textarea { width: 100%; padding: 6px; margin-top: 4px; box-sizing: border-box; border: 1px solid #ccc; border-radius: 4px; font-family: inherit; }
    textarea { height: 60px; resize: vertical; }
    .chat-only { display: none; }
    button { margin-top: 18px; padding: 8px 28px; cursor: pointer; }
    #saved { color: green; display: none; margin-left: 8px; }
    small { color: #666; }
  </style>
</head>
<body>
  <h2>Ollama Spam Filter Settings</h2>

  <label for="ollamaUrl">Ollama URL</label>
  <input type="text" id="ollamaUrl" placeholder="http://localhost:11434">

  <label for="model">Model</label>
  <input type="text" id="model" placeholder="gemma3:12b">
  <small>e.g. gemma3:12b, gemma3:4b, qwen3:8b</small>

  <label for="modelType">Model Type</label>
  <select id="modelType">
    <option value="classify">Classify (returns 0/1 via /api/generate)</option>
    <option value="chat">Chat (structured JSON via /api/chat)</option>
  </select>

  <div id="chatOptions" class="chat-only">
    <label for="systemPrompt">System Prompt</label>
    <textarea id="systemPrompt"></textarea>
  </div>

  <label for="spamAction">When spam is detected</label>
  <select id="spamAction">
    <option value="junk">Move to Junk</option>
    <option value="trash">Move to Trash</option>
    <option value="delete">Delete Permanently</option>
  </select>

  <label for="confidenceThreshold">Confidence Threshold (0.0 - 1.0)</label>
  <input type="number" id="confidenceThreshold" min="0" max="1" step="0.05">

  <label for="concurrency">Concurrency</label>
  <input type="number" id="concurrency" min="1" max="16" step="1">
  <small>Number of parallel classification requests. Match to Ollama's OLLAMA_NUM_PARALLEL (default: 4).</small>

  <label for="maxBodyChars">Max Body Characters</label>
  <input type="number" id="maxBodyChars" min="500" max="32000" step="500">
  <small>Email body is truncated to this length before sending to the model. Lower = faster inference, higher = more context (default: 4000).</small>

  <label for="contextSize">Context Size (num_ctx)</label>
  <input type="number" id="contextSize" min="1024" max="131072" step="1024">
  <small>LLM context window in tokens. Must be large enough to fit system prompt + email metadata + body. Larger values use more VRAM (default: 8192).</small>

  <label style="margin-top: 14px; display: flex; align-items: center; gap: 8px;">
    <input type="checkbox" id="logConversations" style="width: auto;">
    Log classifications to console
  </label>
  <small>Logs email subject and model response to the debug console (Tools &gt; Developer Tools). Email body is not logged.</small>

  <button id="saveBtn">Save</button>
  <span id="saved">Saved!</span>

  <script src="options.js"></script>
</body>
</html>
